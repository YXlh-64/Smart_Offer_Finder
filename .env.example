# Smart Offer Finder - Environment Configuration
# Copy this file to .env and fill in your actual values

# ============================================================
# Pinecone Configuration (REQUIRED)
# ============================================================
# Get these from https://app.pinecone.io/

# Your Pinecone API key (found in API Keys section)
PINECONE_API_KEY=pcak-xxxxxxxxxxx

# The name of your Pinecone index
# Create this in Pinecone dashboard with 384 dimensions (for multilingual-e5-base)
PINECONE_INDEX_NAME=smart-offer-finder

# Your Pinecone environment (shown next to your index, e.g., us-east-1-abc1d23)
PINECONE_ENVIRONMENT=us-east-1-abc1d23

# ============================================================
# Ollama Configuration (REQUIRED)
# ============================================================
# Ollama provides local embeddings and LLM inference

# URL where Ollama is running
# Change this if Ollama is on a different machine or port
OLLAMA_BASE_URL=http://localhost:11434

# Embedding model - for multilingual documents
# Must have pulled this model: ollama pull multilingual-e5-base
EMBEDDING_MODEL=ollama/multilingual-e5-base

# ============================================================
# LLM Configuration (REQUIRED)
# ============================================================
# Choose ONE of the following setups:

# OPTION 1: Local Ollama LLM (Recommended - Free, Private)
LLM_MODEL=ollama/mistral
# Other options: ollama/neural-chat, ollama/llama2, ollama/openchat, ollama/orca-mini

# OPTION 2: OpenAI GPT (Requires API key)
# Uncomment these and comment out the Ollama option above
# LLM_MODEL=gpt-4
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_API_KEY=sk-xxxxxxxxxxxxxxxx

# OPTION 3: Other API providers
# Example for OpenRouter (supports many models)
# LLM_MODEL=gpt-4o
# LLM_BASE_URL=https://openrouter.ai/api/v1
# LLM_API_KEY=sk-or-xxxxxxxxxxxxxxxx

# ============================================================
# Document Ingestion Configuration (OPTIONAL)
# ============================================================
# These control how documents are processed

# Size of text chunks (tokens)
CHUNK_SIZE=800

# Overlap between consecutive chunks (tokens)
CHUNK_OVERLAP=120

# Path to store vectorstore (unused with Pinecone, kept for compatibility)
VECTORSTORE_PATH=data/vectorstore
